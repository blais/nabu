#!/usr/bin/env python
#
# $Source$
# $Id$
#

"""
Nabu restructuredText Reader Extractor.

Usage:
   nabu-publish [<options>] <dir-or-file> [<dir-or-file> ...]

This program read some input text files, identifies and extracts meaningful
information chunks from them, such as addresses and contact info, bookmarks and
links, quotes, and much more.  The goal is for the automatic extraction and
classification of this information in order to publish it in a database, on top
of which various specialized views can be made available.

We want this extraction and publication system to work incrementally, to speed
up the process.  Also, the organization of the source files should be
independent of the organization of the data in the database.

For more details, see the design document that comes with Nabu.
"""

# stdlib imports
import pickle
import xmlrpclib

try: # set the locale to the user settings.
    import locale
    locale.setlocale(locale.LC_ALL, '')
except:
    pass

## FIXME we want to make it so that the find_to_publish algorithm is inside this
## file, so that we can distribute just a single script with no libraries for
## those who will not process locally (simpler, no need for any third party
## libraries).  FIXME TODO

# nabu imports
from nabu.finder import find_to_publish
from nabu import history, process

server_def = 'http://furius.local.biz/nabu/cgi-bin/nabu-publish-handler.cgi'

def main():
    """
    Main program of publisher client.
    """
    import optparse
    parser = optparse.OptionParser(__doc__.strip())

    parser.add_option('-v', '--verbose', action='store_true',
                      help="Increase verbosity")

    parser.add_option('-N', '--no-recurse', '--dont-recurse',
                      action='store_false', dest='recursive', default=True,
                      help="Disable recursion for directories.")

    parser.add_option('-s', '--server-url', action='store', default=server_def,
                      help="URL to server handler.")

    parser.add_option('-f', '--force', action='store_true',
                      help="Force sending/processing all files regardless "
                      "of history.")

    parser.add_option('-l', '--process-locally', action='store_true',
                      help="Process documents in the publisher.")

## FIXME add user/password options, maybe query for password?

    opts, args = parser.parse_args()


    # create server connection
    server = xmlrpclib.ServerProxy(opts.server_url, allow_none=1)

    # find candidate files to consider
    candidates = find_to_publish(args, opts.recursive, opts.verbose)

    # check candidates against history (if not suppressed)
    if opts.force:
        proclist = candidates
    else:
        history_getter = history.NetworkHistoryGetter(server)
        idhistory = history_getter.gethistory([x.unid for x in candidates])

        # compare digests and figure out which files to process
        proclist = []
        for candidate in candidates:
            try:
                hist_digest = idhistory[candidate.unid]
            except KeyError:
                hist_digest = None

            if candidate.digest != hist_digest:
                proclist.append(candidate)

    # process selected files
    for pfile in proclist:
        if not opts.process_locally:
            print '== sending for processing', pfile.fn
            server.process_file(pfile.unid, pfile.fn,
                                xmlrpclib.Binary(pfile.contents))
        else:
            from nabu import process
            contents_uni = pfile.contents.decode('utf-8')
            entries = process.process_source(contents_uni)


if __name__ == '__main__':
    main()
