============
 TODO: nabu
============

:publisher:
- find a good strategy to deal with errors gracefully
  - do we even bother entering partial data when there are errors?
    make it an option on the server?

  - errors should be stored in the NabuSource table

    - provide a way to retrieve the errors from the command-line tool

  - some servers process immediately, return error description

  - we need to find out if it is possible from a CGI script to let the client
    know that we're done, and to keep running on the server, while letting the
    client exit?  note that there might be some options in the client for that
    purpose. find out.



- removing files:
  - add a remove function, to remove content from files that are gone

    - this offers a way to cleanup by considering only the files that are
      present (could be fast, like another clean method, but just for the files
      that aren't found in this pass)

- setup automated publish on commit using
  - CVS
  - Subversion
  ---> and document!

- support encrypted files from the publisher

  - problem: how do we identify documents to be published without decrypting?



:server setup and beta users:
- separate the nabu transforms from the standalone reader transforms and keep
  that as the source documents

  * eventually we could reprocess the entire documents without uploading again,
    just having to run the nabu transforms/extractors

- add parameters to the nabu-contents.cgi script:
  - user (required)
  - type (optional, if not present print list)
  - rendering is for debugging: generic field/value style

- add users to the storage and contents fetching script
  - setup CGI on my server
  - write a script to add databases for new users
  - send script to friends to try it out

- add upload date to all material stored in the database
- add upload user to all material stored in the database
  - this way, multiple users can fill in the same "nabu" storage to 
    produce shared content

- automatically adding columns for entry "fields" that are not currently
  in the database, makes the data model looser

  - find out how to programmatically add columns to the database

- make the server run with multiple threads to process all files after
  communication

- database locking issues?




:entries:
- warn on files that have no titles (add minimum requirements entryform)

- find a way for the entryforms to be "loosely coupled" with the data model on
  the server.

- add a generic field list parser for creating new types of records without
  code: the entry type is the first field list, if it matches some pattern
  (e.g. if it's empty);

- comment nodes could be stripped off complete

- there should be and .. end directive to stop the processing from that point on.
  - .. disclosure:: private directive could achieve something similar



:documentation:
- create home page to describe what it is;

- naming: 

  * Tinba: Tinba Is Not a Blog A...
  * xNB: x is not a blog
  * NABO: Not A Blog Only




:tests:
  - test with other encodings than utf-8 in source files
  - duplicate Id error test


:source files:
- uniformize the :Id: tags


Rejected or Indefinitely-postponed Ideas
----------------------------------------

- ``include-only`` option in the publisher:

    - restrict finder to certain extensions (default is all files)
      - test with .txt extensions

  For now, we think that the ``exclude`` option combined with the
  discrimintation of having markers in only certain files is sufficient for most
  usage.  And you can customize the marker.  Also, since we're just reading the
  header of the files, it is still really fast even when there are a lot of
  large binary files.

- extend the server to allow the publisher to send already parsed doctree as
  pickled to the server.

  We can do this later: this is only an optimization to ease the load on the
  server.
